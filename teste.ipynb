{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Studying Data Science Through Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Data Extraction\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "irisDataset = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', \n",
    "                          names=['sepal length','sepal width','petal length','petal width','class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Data Exploration\n",
    "\n",
    "irisDataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irisDataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(irisDataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pg = sns.PairGrid(irisDataset, hue='class')\n",
    "pg.map_lower(sns.scatterplot)\n",
    "pg.map_diag(plt.hist)\n",
    "pg.map_upper(sns.kdeplot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = sns.diverging_palette(10, 220, as_cmap=True)\n",
    "sns.heatmap(irisDataset.corr(), annot=True, cmap=cmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Data Preparation\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ss = StandardScaler().fit(irisDataset.iloc[:,:-1])\n",
    "\n",
    "x = irisDataset.iloc[:,:-1]\n",
    "y = irisDataset.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y, train_size=0.75, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Data Modeling & Model Evaluation\n",
    "#4.1 Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lrPredict = lr.predict(X_test)\n",
    "\n",
    "lrcv = LogisticRegressionCV(cv=3)\n",
    "lrcv.fit(x, y)\n",
    "lrcvPredict = lrcv.predict(x)\n",
    "lrcvScore = lrcv.score(x,y)\n",
    "\n",
    "print(\"Logistic Regression:\", accuracy_score(lrPredict, y_test))\n",
    "print( confusion_matrix(lrPredict, y_test))\n",
    "print(\"Logistic Regression CV:\", lrcvScore)\n",
    "print( confusion_matrix(lrcvPredict, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.2 Tree classifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=random_state)\n",
    "rf = RandomForestClassifier(random_state=random_state)\n",
    "et = ExtraTreesClassifier(random_state=random_state)\n",
    "\n",
    "print(\"Decision Tree: \", cross_validate(dt, x, y, cv=5)['test_score'])\n",
    "print(\"RandomForest: \", cross_val_score(rf, x, y, cv=5))\n",
    "print(\"ExtraTreesClassifier: \", cross_val_score(et, x, y, cv=5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.3 KNN\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "gs = GridSearchCV(KNeighborsClassifier(),param_grid={ 'n_neighbors' : [3,4,5] },cv=5)\n",
    "gs.fit(x,y)\n",
    "knn = gs.best_estimator_\n",
    "knnPredict = knn.predict(x)\n",
    "print(\"KNN: \", accuracy_score(knnPredict,y), \"\\nBest Params: \", knn.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.4 Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Gaussian: \", cross_val_score(GaussianNB(),x,y,cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.5 SVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "params = { 'svc__C': [1.0, 1.1, 1.2] }\n",
    "pipe = Pipeline([('normalize', StandardScaler()) ,('pca', PCA() ), ('svc', SVC())])\n",
    "svcGs = GridSearchCV(estimator=pipe, param_grid=params,cv=3)\n",
    "svcGs.fit(x,y)\n",
    "pd.DataFrame(svcGs.cv_results_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.6 Neural Network\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "params = {}\n",
    "pipe = Pipeline([ (\"neural\", MLPClassifier()) ])\n",
    "gsMLP = GridSearchCV(estimator=pipe, param_grid=params, cv=3)\n",
    "gsMLP.fit(x,y)\n",
    "pd.DataFrame(gsMLP.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.7 Deep Learning\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lb = LabelEncoder().fit(y)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim = 4 , activation = 'relu'))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(6, activation = 'relu'))\n",
    "model.add(Dense(3, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy' , optimizer = 'adam' , metrics = ['accuracy'] )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, to_categorical(lb.transform(y_train.values)), epochs=110)\n",
    "model.evaluate(X_test, to_categorical(lb.transform(y_test.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
